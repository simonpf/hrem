{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a1fb5a9-eeeb-462e-af20-254d7c53d0ef",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "This notebook runs the ML heating-rate emulator on the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff63be7-6986-41d3-81ce-f0248c37ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29cc6ec-e87d-4343-bab3-816809c7fd4b",
   "metadata": {},
   "source": [
    "## Models and Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1771922a-f3e0-488a-b00d-629ea81c9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_retrieve import load_model\n",
    "from hrem.datasets import HREMDataset0, HREMDataset1, HREMDataset2, HREMDataset3, HREMDataset4, HREMDataset5\n",
    "\n",
    "model_path = Path(\"/home/simon/src/hrem/models/\")\n",
    "data_path = Path(\"/home/simon/data/heating_rates/4Simon/\")\n",
    "\n",
    "models = {\n",
    "    \"V2.0\": (\n",
    "        model_path / \"v2.0\" / \"hrem_v2_0.pt\",\n",
    "        HREMDataset0(data_path / \"HR_test_patches.zarr/\", validation=True),\n",
    "    ),\n",
    "    \"V2.1\": (\n",
    "        model_path / \"v2.1\" / \"hrem_v2_1.pt\",\n",
    "        HREMDataset1(data_path / \"HR_test_patches_withLWPReff.zarr/\", validation=True),\n",
    "    ),\n",
    "    \"V2.2\": (\n",
    "        model_path / \"v2.2\" / \"hrem_v2_2.pt\",\n",
    "        HREMDataset2(data_path / \"HR_test_patches_with_split_bands.zarr/\", validation=True),\n",
    "    ),\n",
    "    \"V2.3\": (\n",
    "        model_path / \"v2.3\" / \"hrem_v2_3.pt\",\n",
    "        HREMDataset3(data_path / \"HR_test_patches_with_split_bands_and_tau.zarr/\", validation=True),\n",
    "    ),\n",
    "    \"V2.4\": (\n",
    "        model_path / \"v2.4\" / \"hrem_v2_4.pt\",\n",
    "        HREMDataset4(data_path / \"HR_test_patches_with_split_bands_and_tau.zarr/\", validation=True),\n",
    "    ),\n",
    "    \"V2.4s\": (\n",
    "        model_path / \"v2.4s\" / \"hrem_v2_4_s.pt\",\n",
    "        HREMDataset4(data_path / \"HR_test_patches_with_split_bands_and_tau.zarr/\", validation=True),\n",
    "    ),\n",
    "    \"V2.5\": (\n",
    "        model_path / \"v2.5\" / \"hrem_v2_5.pt\",\n",
    "        HREMDataset5(\n",
    "            data_path / \"HR_test_patches_with_split_bands_and_tau.zarr/\",\n",
    "            data_path / \"HR_test_CKD_level_vars.nc\",\n",
    "            validation=True\n",
    "        ),\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bd725-0c35-4dd2-ac4d-3b96f123bb80",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0008a66c-0026-4c45-bb18-a4c965c6bfa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 384/384 [03:57<00:00,  1.61it/s]\n",
      "  0%|                                                                                                              | 0/384 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m version, (model, ds) \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m      4\u001b[39m     mdl = load_model(model).eval()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     results, reference = \u001b[43mrun_emulator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda:0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     output_zarr = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresults_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.zarr\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m     root = zarr.open_group(output_zarr, mode=\u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/hrem/utils.py:254\u001b[39m, in \u001b[36mrun_emulator\u001b[39m\u001b[34m(model, data_loader, device, dtype)\u001b[39m\n\u001b[32m    251\u001b[39m results = []\n\u001b[32m    252\u001b[39m reference = []\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msimulate_fluxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minpt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/torch/utils/data/dataloader.py:732\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    730\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    731\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m732\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    734\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    735\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    736\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    738\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/torch/utils/data/dataloader.py:788\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    787\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    789\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    790\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/hrem/datasets/__init__.py:866\u001b[39m, in \u001b[36mHREMDataset5.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx >= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    864\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIndex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m out of range for dataset of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m inputs, target = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.validation)  \u001b[38;5;129;01mand\u001b[39;00m \u001b[32m0.5\u001b[39m  < \u001b[38;5;28mself\u001b[39m.rng.random():\n\u001b[32m    869\u001b[39m     inputs = torch.flip(inputs, (-\u001b[32m2\u001b[39m,))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/hrem/datasets/__init__.py:826\u001b[39m, in \u001b[36mHREMDataset5._get_sample\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    823\u001b[39m target = np.array(outputs[idx])\n\u001b[32m    824\u001b[39m target = np.transpose(target, (\u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m826\u001b[39m profiles = torch.from_numpy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_profiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m).float()[..., \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[32m    827\u001b[39m profiles = torch.broadcast_to(profiles, (\u001b[32m4\u001b[39m,) + inputs.shape[\u001b[32m1\u001b[39m:])\n\u001b[32m    828\u001b[39m inputs = np.concatenate([inputs, profiles], axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/hrem/datasets/__init__.py:792\u001b[39m, in \u001b[36mHREMDataset5.get_profiles\u001b[39m\u001b[34m(self, file_ind, ind)\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[33;03mLoad profiles for given case.\u001b[39;00m\n\u001b[32m    787\u001b[39m \n\u001b[32m    788\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    789\u001b[39m \u001b[33;03m    ind: The index of the scene for which to load  the profile.\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    791\u001b[39m ind = ind // \u001b[32m192\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprofile_file_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_ind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m profile_data:\n\u001b[32m    793\u001b[39m     temp = profile_data.Temp[{\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: ind}].compute().data\n\u001b[32m    794\u001b[39m     pres = profile_data.Pres[{\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: ind}].compute().data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/xarray/backends/api.py:577\u001b[39m, in \u001b[36mopen_dataset\u001b[39m\u001b[34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, create_default_indexes, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[39m\n\u001b[32m    574\u001b[39m     kwargs.update(backend_kwargs)\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m     engine = \u001b[43mplugins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    580\u001b[39m     from_array_kwargs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/xarray/backends/plugins.py:212\u001b[39m, in \u001b[36mguess_engine\u001b[39m\u001b[34m(store_spec, must_support_groups)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    205\u001b[39m     error_msg = (\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfound the following matches with the input file in xarray\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms IO \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    210\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[31mValueError\u001b[39m: found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html"
     ]
    }
   ],
   "source": [
    "import zarr\n",
    "from hrem.utils import run_emulator\n",
    "for version, (model, ds) in models.items():\n",
    "    mdl = load_model(model).eval()\n",
    "    results, reference = run_emulator(mdl, ds, device=\"cuda:0\")\n",
    "    output_zarr = f\"results_{version}.zarr\"\n",
    "    root = zarr.open_group(output_zarr, mode='w')\n",
    "    root[\"CNN_output\"] = results\n",
    "    del root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0e8a41-6804-4515-b096-e1faeb218dae",
   "metadata": {},
   "source": [
    "## Error Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4498d277-dc55-4a26-bd37-57467be5777a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from hrem.utils import evaluate_scene\n",
    "\n",
    "def evaluate_model(model, dataset):\n",
    "    \"\"\"\n",
    "    Calculate error statistics for model configuration.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model instance.\n",
    "        dataset: The dataset to load the input data.\n",
    "\n",
    "    Return:\n",
    "        An xarray.Dataset containing the error statistics.\n",
    "    \"\"\"\n",
    "    rel_err_bins = np.linspace(-50, 50, 101)\n",
    "    err_bins = np.linspace(-100, 100, 101)\n",
    "    \n",
    "    err_cs_sum = 0.0\n",
    "    abs_err_cs_sum = 0.0\n",
    "    squared_err_cs_sum = 0.0\n",
    "    rel_err_cs_sum = 0.0\n",
    "    rel_abs_err_cs_sum = 0.0\n",
    "    cts_cs = 0.0\n",
    "    hr_ref_cs_sum = 0.0\n",
    "    rel_err_dist_cs = np.zeros((16, 100))\n",
    "    err_dist_cs = np.zeros((16, 100))\n",
    "    \n",
    "    rel_err_ic_sum = 0.0\n",
    "    rel_abs_err_ic_sum = 0.0\n",
    "    abs_err_ic_sum = 0.0\n",
    "    squared_err_ic_sum = 0.0\n",
    "    err_ic_sum = 0.0\n",
    "    cts_ic = 0.0\n",
    "    hr_ref_ic_sum = 0.0\n",
    "    rel_err_dist_ic = np.zeros((16, 100))\n",
    "    err_dist_ic = np.zeros((16, 100))\n",
    "    \n",
    "    for case in tqdm(range(16)):\n",
    "        hr_pred, hr_ref, cloud_mask = evaluate_scene(model, dataset, case, device=\"cuda:0\", dtype=torch.bfloat16)\n",
    "\n",
    "        # Clear Sky Stats\n",
    "        hr_pred_cs = hr_pred[~cloud_mask]\n",
    "        hr_ref_cs = hr_ref[~cloud_mask]\n",
    "        \n",
    "        err_cs = hr_pred_cs - hr_ref_cs\n",
    "        abs_err_cs = np.abs(err_cs)\n",
    "        squared_err_cs = err_cs ** 2\n",
    "        rel_err_cs = err_cs / hr_ref_cs\n",
    "        rel_abs_err_cs = abs_err_cs / hr_ref_cs\n",
    "\n",
    "        err_cs_sum += err_cs.sum()\n",
    "        abs_err_cs_sum += abs_err_cs.sum()\n",
    "        squared_err_cs_sum += squared_err_cs.sum()\n",
    "        rel_err_cs_sum += rel_err_cs.sum()\n",
    "        rel_abs_err_cs_sum += rel_abs_err_cs.sum()\n",
    "        hr_ref_cs_sum += hr_ref_cs.sum()\n",
    "        cts_cs += (~cloud_mask).sum()\n",
    "        \n",
    "        rel_err_dist_cs[case] += np.histogram(100.0 * rel_err_cs, bins=rel_err_bins)[0]\n",
    "        err_dist_cs[case] += np.histogram(err_cs, bins=err_bins)[0]\n",
    "        \n",
    "        # Cloudy Sky Stats\n",
    "        hr_pred_ic = hr_pred[cloud_mask]\n",
    "        hr_ref_ic = hr_ref[cloud_mask]\n",
    "        \n",
    "        err_ic = hr_pred_ic - hr_ref_ic\n",
    "        abs_err_ic = np.abs(err_ic)\n",
    "        squared_err_ic = err_ic ** 2\n",
    "        rel_err_ic = err_ic / hr_ref_ic\n",
    "        rel_abs_err_ic = abs_err_ic / hr_ref_ic\n",
    "\n",
    "        err_ic_sum += err_ic.sum()\n",
    "        abs_err_ic_sum += abs_err_ic.sum()\n",
    "        squared_err_ic_sum += squared_err_ic.sum()\n",
    "        rel_err_ic_sum += rel_err_ic.sum()\n",
    "        rel_abs_err_ic_sum += rel_abs_err_ic.sum()\n",
    "        hr_ref_ic_sum += hr_ref_ic.sum()\n",
    "        cts_ic += (cloud_mask).sum()\n",
    "\n",
    "        rel_err_dist_ic[case] += np.histogram(100.0 * rel_err_ic, bins=rel_err_bins)[0]\n",
    "        err_dist_ic[case] += np.histogram(err_ic, bins=err_bins)[0]\n",
    "\n",
    "    hr_ref_cs = hr_ref_cs_sum / cts_cs\n",
    "    hr_ref_ic = hr_ref_ic_sum / cts_ic\n",
    "    hr_ref = (hr_ref_cs_sum + hr_ref_ic_sum) / (cts_cs + cts_ic)\n",
    "    \n",
    "    bias_cs = err_cs_sum / cts_cs\n",
    "    bias_ic = err_ic_sum / cts_ic\n",
    "    bias = (err_cs_sum + err_ic_sum) / (cts_cs + cts_ic)\n",
    "    \n",
    "    rel_bias_cs = 100.0 * bias_cs / hr_ref_cs\n",
    "    rel_bias_ic = 100.0 * bias_ic / hr_ref_ic\n",
    "    rel_bias= 100.0 * bias/ hr_ref\n",
    "\n",
    "    abs_err_ic = abs_err_ic_sum / cts_ic\n",
    "    abs_err_cs = abs_err_cs_sum / cts_cs\n",
    "    abs_err = (abs_err_ic_sum + abs_err_cs_sum) / (cts_ic + cts_cs)\n",
    "    \n",
    "    squared_err_ic = squared_err_ic_sum / cts_ic\n",
    "    squared_err_cs = squared_err_cs_sum / cts_cs\n",
    "    squared_err = (squared_err_ic_sum + squared_err_cs_sum) / (cts_ic + cts_cs)\n",
    "    \n",
    "    rel_err_ic = rel_err_ic_sum / cts_ic\n",
    "    rel_err_cs = rel_err_cs_sum / cts_cs\n",
    "    rel_err = (rel_err_ic_sum + rel_err_cs_sum) / (cts_ic + cts_cs)\n",
    "    \n",
    "    rel_abs_err_ic = rel_abs_err_ic_sum / cts_ic\n",
    "    rel_abs_err_cs = rel_abs_err_cs_sum / cts_cs\n",
    "    rel_abs_err = (rel_abs_err_ic_sum + rel_abs_err_cs_sum) / (cts_ic + cts_cs)\n",
    "\n",
    "    rel_err_dist = rel_err_dist_cs + rel_err_dist_ic\n",
    "    err_dist = err_dist_cs + err_dist_ic\n",
    "\n",
    "    rel_err_bin = 0.5 * (rel_err_bins[1:] + rel_err_bins[:-1])\n",
    "    err_bin = 0.5 * (err_bins[1:] + err_bins[:-1])\n",
    "\n",
    "    return xr.Dataset({\n",
    "        \"bias_cs\": bias_cs,\n",
    "        \"bias_ic\": bias_ic,\n",
    "        \"bias\": bias,\n",
    "        \"rel_bias_cs\": rel_bias_cs,\n",
    "        \"rel_bias_ic\": rel_bias_ic,\n",
    "        \"rel_bias\": rel_bias,\n",
    "        \"abs_err_ic\": abs_err_ic,\n",
    "        \"abs_err_cs\": abs_err_cs,\n",
    "        \"abs_err\": abs_err,\n",
    "        \"squared_err_ic\": squared_err_ic,\n",
    "        \"squared_err_cs\": squared_err_cs,\n",
    "        \"squared_err\": squared_err,\n",
    "        \"rel_err_ic\": rel_err_ic,\n",
    "        \"rel_err_cs\": rel_err_cs,\n",
    "        \"rel_err\": rel_err,\n",
    "        \"rel_abs_err_ic\": rel_abs_err_ic,\n",
    "        \"rel_abs_err_cs\": rel_abs_err_cs,\n",
    "        \"rel_abs_err\": rel_abs_err,\n",
    "        \"rel_err_bin\": ((\"rel_err_bin\",), rel_err_bin),\n",
    "        \"rel_err_dist_cs\": ((\"case\", \"rel_err_bin\",), rel_err_dist_cs),\n",
    "        \"rel_err_dist_ic\": ((\"case\", \"rel_err_bin\",), rel_err_dist_ic),\n",
    "        \"rel_err_dist\": ((\"case\", \"rel_err_bin\",), rel_err_dist),\n",
    "        \"err_bin\": ((\"err_bin\",), err_bin),\n",
    "        \"err_dist_cs\": ((\"case\", \"err_bin\",), err_dist_cs),\n",
    "        \"err_dist_ic\": ((\"case\", \"err_bin\",), err_dist_ic),\n",
    "        \"err_dist\": ((\"case\", \"err_bin\",), err_dist),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cde86f43-a468-48f0-bda7-b2c6d9ba4c39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                | 0/2 [00:00<?, ?it/s]\n",
      "  0%|                                                                                                               | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      "  6%|██████▍                                                                                                | 1/16 [00:27<06:58, 27.91s/it]\u001b[A\n",
      " 12%|████████████▉                                                                                          | 2/16 [00:45<05:06, 21.91s/it]\u001b[A\n",
      " 19%|███████████████████▎                                                                                   | 3/16 [01:03<04:18, 19.90s/it]\u001b[A\n",
      " 25%|█████████████████████████▊                                                                             | 4/16 [01:20<03:47, 18.93s/it]\u001b[A\n",
      " 31%|████████████████████████████████▏                                                                      | 5/16 [01:37<03:21, 18.34s/it]\u001b[A\n",
      " 38%|██████████████████████████████████████▋                                                                | 6/16 [01:55<02:59, 18.00s/it]\u001b[A\n",
      " 44%|█████████████████████████████████████████████                                                          | 7/16 [02:12<02:40, 17.86s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████▌                                                   | 8/16 [02:30<02:21, 17.70s/it]\u001b[A\n",
      " 56%|█████████████████████████████████████████████████████████▉                                             | 9/16 [02:47<02:03, 17.60s/it]\u001b[A\n",
      " 62%|███████████████████████████████████████████████████████████████▊                                      | 10/16 [03:04<01:45, 17.52s/it]\u001b[A\n",
      " 69%|██████████████████████████████████████████████████████████████████████▏                               | 11/16 [03:22<01:27, 17.52s/it]\u001b[A\n",
      " 75%|████████████████████████████████████████████████████████████████████████████▌                         | 12/16 [03:39<01:09, 17.46s/it]\u001b[A\n",
      " 81%|██████████████████████████████████████████████████████████████████████████████████▉                   | 13/16 [03:57<00:52, 17.49s/it]\u001b[A\n",
      " 88%|█████████████████████████████████████████████████████████████████████████████████████████▎            | 14/16 [04:14<00:34, 17.46s/it]\u001b[A\n",
      " 94%|███████████████████████████████████████████████████████████████████████████████████████████████▋      | 15/16 [04:31<00:17, 17.42s/it]\u001b[A\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [04:49<00:00, 18.08s/it]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████▌                                                   | 1/2 [04:49<04:49, 289.36s/it]\n",
      "  0%|                                                                                                               | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|███████████████████████████████████████████████████▌                                                   | 1/2 [04:49<04:49, 289.42s/it]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m version, (model, ds) \u001b[38;5;129;01min\u001b[39;00m tqdm(models.items()):\n\u001b[32m      5\u001b[39m     mdl = load_model(model).eval()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     res = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     res[\u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m] = version\n\u001b[32m      8\u001b[39m     res.to_netcdf(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mresults_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.nc\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, dataset)\u001b[39m\n\u001b[32m     37\u001b[39m err_dist_ic = np.zeros((\u001b[32m16\u001b[39m, \u001b[32m100\u001b[39m))\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m case \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m16\u001b[39m)):\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     hr_pred, hr_ref, cloud_mask = \u001b[43mevaluate_scene\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda:0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbfloat16\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m# Clear Sky Stats\u001b[39;00m\n\u001b[32m     43\u001b[39m     hr_pred_cs = hr_pred[~cloud_mask]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/hrem/utils.py:81\u001b[39m, in \u001b[36mevaluate_scene\u001b[39m\u001b[34m(model, data_loader, scene, device, dtype)\u001b[39m\n\u001b[32m     78\u001b[39m cloud_mask = []\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_ind, end_ind, \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     inpt, ref = \u001b[43mdata_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     82\u001b[39m     pred = simulate_fluxes(model, inpt, device=device, dtype=dtype)\n\u001b[32m     83\u001b[39m     cloud_mask.append(data_loader.get_cloud_mask(ind)[:, \u001b[32m5\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/hrem/datasets/__init__.py:866\u001b[39m, in \u001b[36mHREMDataset5.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    863\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m idx >= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    864\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIndex \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m out of range for dataset of length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m inputs, target = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.validation)  \u001b[38;5;129;01mand\u001b[39;00m \u001b[32m0.5\u001b[39m  < \u001b[38;5;28mself\u001b[39m.rng.random():\n\u001b[32m    869\u001b[39m     inputs = torch.flip(inputs, (-\u001b[32m2\u001b[39m,))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/hrem/datasets/__init__.py:826\u001b[39m, in \u001b[36mHREMDataset5._get_sample\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m    823\u001b[39m target = np.array(outputs[idx])\n\u001b[32m    824\u001b[39m target = np.transpose(target, (\u001b[32m3\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m826\u001b[39m profiles = torch.from_numpy(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_profiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m).float()[..., \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[32m    827\u001b[39m profiles = torch.broadcast_to(profiles, (\u001b[32m4\u001b[39m,) + inputs.shape[\u001b[32m1\u001b[39m:])\n\u001b[32m    828\u001b[39m inputs = np.concatenate([inputs, profiles], axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/hrem/datasets/__init__.py:792\u001b[39m, in \u001b[36mHREMDataset5.get_profiles\u001b[39m\u001b[34m(self, file_ind, ind)\u001b[39m\n\u001b[32m    785\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[33;03mLoad profiles for given case.\u001b[39;00m\n\u001b[32m    787\u001b[39m \n\u001b[32m    788\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m    789\u001b[39m \u001b[33;03m    ind: The index of the scene for which to load  the profile.\u001b[39;00m\n\u001b[32m    790\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    791\u001b[39m ind = ind // \u001b[32m192\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mxr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprofile_file_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfile_ind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m profile_data:\n\u001b[32m    793\u001b[39m     temp = profile_data.Temp[{\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: ind}].compute().data\n\u001b[32m    794\u001b[39m     pres = profile_data.Pres[{\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: ind}].compute().data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/xarray/backends/api.py:577\u001b[39m, in \u001b[36mopen_dataset\u001b[39m\u001b[34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, create_default_indexes, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[39m\n\u001b[32m    574\u001b[39m     kwargs.update(backend_kwargs)\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m     engine = \u001b[43mplugins\u001b[49m\u001b[43m.\u001b[49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    580\u001b[39m     from_array_kwargs = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/hrem/lib/python3.11/site-packages/xarray/backends/plugins.py:212\u001b[39m, in \u001b[36mguess_engine\u001b[39m\u001b[34m(store_spec, must_support_groups)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    205\u001b[39m     error_msg = (\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfound the following matches with the input file in xarray\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms IO \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    208\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    209\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    210\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[31mValueError\u001b[39m: found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "tasks = {}\n",
    "for version, (model, ds) in tqdm(models.items()):\n",
    "    mdl = load_model(model).eval()\n",
    "    res = evaluate_model(mdl, ds)\n",
    "    res[\"version\"] = version\n",
    "    res.to_netcdf(f\"results_{version}.nc\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
